{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist_vec = np.random.rand(387, 2350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/FID-300/\"\n",
    "divided_data_path = os.path.join(data_path, \"divided\")\n",
    "\n",
    "label_file = os.path.join(data_path,'label_table_train.csv')\n",
    "label_map = np.loadtxt(label_file,delimiter=',',dtype='int')\n",
    "label_file = os.path.join(divided_data_path,'label_table_train.csv')\n",
    "div_label_map = np.loadtxt(label_file,delimiter=',',dtype='int')\n",
    "\n",
    "label_table = label_map[:, 1]\n",
    "\n",
    "div_lhs = div_label_map[:, 0]\n",
    "lhs = label_map[:, 0]\n",
    "\n",
    "scores = np.zeros((len(label_map), 1175))\n",
    "\n",
    "# DIstance from upper/Lower shoe features\n",
    "du = l2_dist_vec.reshape(-1, int(l2_dist_vec.shape[1]/2), 2)[:, :, 0]\n",
    "dl = l2_dist_vec.reshape(-1, int(l2_dist_vec.shape[1]/2), 2)[:, :, 1]\n",
    "\n",
    "count = 0\n",
    "for i, l in enumerate(lhs):\n",
    "    if 2*l not in div_lhs:\n",
    "        scores[i] = du[count]\n",
    "        count+=1\n",
    "    else:\n",
    "        scores[i] = np.maximum(du[count], dl[count+1])\n",
    "score_sort = scores.argsort(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_sort.shape = (240, 1175)\n",
      "label_table.shape = (240,)\n",
      "label_table = [1044   14 1078   63   11   39 1050    3   37   37   14   14 1056 1064\n",
      "    3   60    3    3   41   33   42    3   48 1069    8   31 1059   19\n",
      " 1081   29   22   34   38    9    9 1059    8 1057  863   27   42 1059\n",
      " 1071 1077 1064   53    1    3   45    4   20    1 1059    5    1   50\n",
      "   69   29   47 1079 1072   69    7 1060   36   49   22   22   14   51\n",
      "   58   24   49   16   64   64 1052 1058   50   49   20 1046 1091   49\n",
      "    5   37 1049   23   71   41 1050   14 1068   66 1041 1050   13   13\n",
      " 1062   56   62   48   57    7    2 1068   54 1053   21    2 1074   15\n",
      " 1075   32 1047 1071 1042 1042   10   57   28   17   43   24   73   47\n",
      "    5    5   11   30 1070   57   63 1080 1073   14    8 1071   37 1076\n",
      " 1080   35 1055   79   39   48 1053   33   68   64   10   52   77 1080\n",
      " 1047 1065 1050   58   43 1067   33   21 1040 1055   12   37 1052   57\n",
      " 1085   58 1080 1083   82   50   49   65   65   73   11 1055 1049   61\n",
      "   29   32   83   27   22   22   21 1055   69 1087 1087 1053   45   12\n",
      "   21   34 1088 1039 1040 1089   68   11 1096   30   30 1044 1094 1085\n",
      "   56   17    4   56   56   49   51 1044   69   17   37   88   20   43\n",
      " 1071   60   60   44 1049   79   88 1055 1044   60   74 1096 1041 1082\n",
      "    5   46]\n"
     ]
    }
   ],
   "source": [
    "print(\"score_sort.shape = {}\".format(score_sort.shape))\n",
    "print(\"label_table.shape = {}\".format(label_table.shape))\n",
    "print(\"label_table = {}\".format(label_table))\n",
    "# label_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_array = []\n",
    "for a, c in zip(score_sort, label_table):\n",
    "    pos_array.append(np.where(a==c)[0][0])\n",
    "    # print(\"match_id ,c\", np.where(a==c)[0][0], c)\n",
    "pos_array = np.array(pos_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_data_path = os.path.join(data_path, \"divided\")\n",
    "\n",
    "ref_path_orig = os.path.join(data_path, \"references\")\n",
    "ref_path = os.path.join(divided_data_path, \"references\")\n",
    "\n",
    "train_path_orig = os.path.join(data_path, \"tracks_cropped_train\")\n",
    "val_path_orig = os.path.join(data_path, \"tracks_cropped_val\")\n",
    "\n",
    "train_path = os.path.join(divided_data_path, \"tracks_cropped_train\")\n",
    "val_path = os.path.join(divided_data_path, \"tracks_cropped_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(divided_data_path):\n",
    "    os.makedirs(divided_data_path)\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    os.makedirs(train_path)\n",
    "    \n",
    "if not os.path.exists(val_path):\n",
    "    os.makedirs(val_path)\n",
    "    \n",
    "if not os.path.exists(ref_path):\n",
    "    os.makedirs(ref_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = os.listdir(ref_path_orig)\n",
    "flist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in flist:\n",
    "    id = int(f[:5])\n",
    "    src = os.path.join(ref_path_orig, f)\n",
    "    I = skimage.io.imread(src)\n",
    "    mid = int(I.shape[0]/2)\n",
    "    I_U = I[:mid, :]\n",
    "    I_B = I[mid:, :]\n",
    "\n",
    "    dst_U = os.path.join(ref_path, \"{:05d}.png\".format(2*id-1))\n",
    "    dst_B = os.path.join(ref_path, \"{:05d}.png\".format(2*id))\n",
    "    skimage.io.imsave(dst_U, I_U)\n",
    "    skimage.io.imsave(dst_B, I_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = os.listdir(train_path_orig)\n",
    "flist.sort()\n",
    "\n",
    "label_file = open(data_path + \"label_table_train.csv\")\n",
    "label_map = np.loadtxt(label_file,delimiter=',',dtype='int')\n",
    "label_dict = dict((a,b) for a,b in label_map)\n",
    "label_map = np.zeros((0,2)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in flist:\n",
    "    src = os.path.join(train_path_orig, f)\n",
    "    I = skimage.io.imread(src)\n",
    "    id = int(f[:5])\n",
    "    \n",
    "    if I.shape[0]/I.shape[1] > 2:\n",
    "        mid = int(I.shape[0]/2)\n",
    "\n",
    "        I_U = I[:mid, :]\n",
    "        dst_U = os.path.join(train_path, \"{:05d}.png\".format(2*id-1))\n",
    "        skimage.io.imsave(dst_U, I_U)\n",
    "\n",
    "        I_B = I[mid:, :]\n",
    "        dst_B = os.path.join(train_path, \"{:05d}.png\".format(2*id))\n",
    "        skimage.io.imsave(dst_B, I_B)\n",
    "        label_map = np.vstack((label_map, [2*id-1, 2*label_dict[id]-1]))\n",
    "        label_map = np.vstack((label_map, [2*id, 2*label_dict[id]]))\n",
    "        \n",
    "    else:\n",
    "        dst_U = os.path.join(train_path, \"{:05d}.png\".format(2*id-1))\n",
    "        skimage.io.imsave(dst_U, I_U)\n",
    "        label_map = np.vstack((label_map, [2*id-1, 2*label_dict[id]-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = os.path.join(divided_data_path, \"label_table_train.csv\")\n",
    "np.savetxt(label_path, label_map, fmt=\"%d\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = os.listdir(val_path_orig)\n",
    "flist.sort()\n",
    "\n",
    "label_file = open(data_path + \"label_table_val.csv\")\n",
    "label_map = np.loadtxt(label_file,delimiter=',',dtype='int')\n",
    "label_dict = dict((a,b) for a,b in label_map)\n",
    "label_map = np.zeros((0,2)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in flist:\n",
    "    src = os.path.join(val_path_orig, f)\n",
    "    I = skimage.io.imread(src)\n",
    "    id = int(f[:5])\n",
    "    \n",
    "    if I.shape[0]/I.shape[1] > 2:\n",
    "        mid = int(I.shape[0]/2)\n",
    "\n",
    "        I_U = I[:mid, :]\n",
    "        dst_U = os.path.join(val_path, \"{:05d}.png\".format(2*id-1))\n",
    "        skimage.io.imsave(dst_U, I_U)\n",
    "\n",
    "        I_B = I[mid:, :]\n",
    "        dst_B = os.path.join(val_path, \"{:05d}.png\".format(2*id))\n",
    "        skimage.io.imsave(dst_B, I_B)\n",
    "        label_map = np.vstack((label_map, [2*id-1, 2*label_dict[id]-1]))\n",
    "        label_map = np.vstack((label_map, [2*id, 2*label_dict[id]]))\n",
    "        \n",
    "    else:\n",
    "        dst_U = os.path.join(val_path, \"{:05d}.png\".format(2*id-1))\n",
    "        skimage.io.imsave(dst_U, I_U)\n",
    "        label_map = np.vstack((label_map, [2*id-1, 2*label_dict[id]-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = os.path.join(divided_data_path, \"label_table_val.csv\")\n",
    "np.savetxt(label_path, label_map, fmt=\"%d\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_file = os.path.join(divided_data_path,'label_table_train.csv')\n",
    "# label_map = np.loadtxt(label_file,delimiter=',',dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = os.path.join(data_path,'label_table_train.csv')\n",
    "label_map = np.loadtxt(label_file,delimiter=',',dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1, 1044],\n",
       "       [   2,   14],\n",
       "       [   4, 1078],\n",
       "       [   5,   63],\n",
       "       [   6,   11],\n",
       "       [   7,   39],\n",
       "       [   8, 1050],\n",
       "       [   9,    3],\n",
       "       [  10,   37],\n",
       "       [  11,   37],\n",
       "       [  12,   14],\n",
       "       [  13,   14],\n",
       "       [  14, 1056],\n",
       "       [  15, 1064],\n",
       "       [  17,    3],\n",
       "       [  19,   60],\n",
       "       [  20,    3],\n",
       "       [  21,    3],\n",
       "       [  22,   41],\n",
       "       [  23,   33],\n",
       "       [  24,   42],\n",
       "       [  25,    3],\n",
       "       [  27,   48],\n",
       "       [  28, 1069],\n",
       "       [  29,    8],\n",
       "       [  30,   31],\n",
       "       [  31, 1059],\n",
       "       [  32,   19],\n",
       "       [  34, 1081],\n",
       "       [  36,   29],\n",
       "       [  37,   22],\n",
       "       [  38,   34],\n",
       "       [  39,   38],\n",
       "       [  41,    9],\n",
       "       [  43,    9],\n",
       "       [  45, 1059],\n",
       "       [  46,    8],\n",
       "       [  48, 1057],\n",
       "       [  49,  863],\n",
       "       [  53,   27],\n",
       "       [  56,   42],\n",
       "       [  57, 1059],\n",
       "       [  58, 1071],\n",
       "       [  59, 1077],\n",
       "       [  62, 1064],\n",
       "       [  63,   53],\n",
       "       [  64,    1],\n",
       "       [  66,    3],\n",
       "       [  67,   45],\n",
       "       [  68,    4],\n",
       "       [  69,   20],\n",
       "       [  70,    1],\n",
       "       [  71, 1059],\n",
       "       [  72,    5],\n",
       "       [  73,    1],\n",
       "       [  74,   50],\n",
       "       [  76,   69],\n",
       "       [  77,   29],\n",
       "       [  78,   47],\n",
       "       [  79, 1079],\n",
       "       [  80, 1072],\n",
       "       [  81,   69],\n",
       "       [  82,    7],\n",
       "       [  83, 1060],\n",
       "       [  84,   36],\n",
       "       [  87,   49],\n",
       "       [  89,   22],\n",
       "       [  90,   22],\n",
       "       [  91,   14],\n",
       "       [  92,   51],\n",
       "       [  93,   58],\n",
       "       [  94,   24],\n",
       "       [  95,   49],\n",
       "       [  97,   16],\n",
       "       [  98,   64],\n",
       "       [  99,   64],\n",
       "       [ 100, 1052],\n",
       "       [ 101, 1058],\n",
       "       [ 103,   50],\n",
       "       [ 104,   49],\n",
       "       [ 105,   20],\n",
       "       [ 107, 1046],\n",
       "       [ 108, 1091],\n",
       "       [ 109,   49],\n",
       "       [ 110,    5],\n",
       "       [ 111,   37],\n",
       "       [ 113, 1049],\n",
       "       [ 114,   23],\n",
       "       [ 115,   71],\n",
       "       [ 116,   41],\n",
       "       [ 117, 1050],\n",
       "       [ 118,   14],\n",
       "       [ 119, 1068],\n",
       "       [ 121,   66],\n",
       "       [ 122, 1041],\n",
       "       [ 123, 1050],\n",
       "       [ 124,   13],\n",
       "       [ 125,   13],\n",
       "       [ 127, 1062],\n",
       "       [ 128,   56],\n",
       "       [ 129,   62],\n",
       "       [ 130,   48],\n",
       "       [ 131,   57],\n",
       "       [ 132,    7],\n",
       "       [ 133,    2],\n",
       "       [ 136, 1068],\n",
       "       [ 137,   54],\n",
       "       [ 138, 1053],\n",
       "       [ 139,   21],\n",
       "       [ 140,    2],\n",
       "       [ 141, 1074],\n",
       "       [ 142,   15],\n",
       "       [ 143, 1075],\n",
       "       [ 144,   32],\n",
       "       [ 145, 1047],\n",
       "       [ 146, 1071],\n",
       "       [ 147, 1042],\n",
       "       [ 148, 1042],\n",
       "       [ 149,   10],\n",
       "       [ 150,   57],\n",
       "       [ 151,   28],\n",
       "       [ 156,   17],\n",
       "       [ 159,   43],\n",
       "       [ 161,   24],\n",
       "       [ 162,   73],\n",
       "       [ 164,   47],\n",
       "       [ 165,    5],\n",
       "       [ 166,    5],\n",
       "       [ 167,   11],\n",
       "       [ 168,   30],\n",
       "       [ 169, 1070],\n",
       "       [ 170,   57],\n",
       "       [ 171,   63],\n",
       "       [ 172, 1080],\n",
       "       [ 173, 1073],\n",
       "       [ 174,   14],\n",
       "       [ 175,    8],\n",
       "       [ 176, 1071],\n",
       "       [ 177,   37],\n",
       "       [ 178, 1076],\n",
       "       [ 179, 1080],\n",
       "       [ 180,   35],\n",
       "       [ 181, 1055],\n",
       "       [ 182,   79],\n",
       "       [ 183,   39],\n",
       "       [ 184,   48],\n",
       "       [ 185, 1053],\n",
       "       [ 186,   33],\n",
       "       [ 187,   68],\n",
       "       [ 188,   64],\n",
       "       [ 189,   10],\n",
       "       [ 190,   52],\n",
       "       [ 191,   77],\n",
       "       [ 192, 1080],\n",
       "       [ 193, 1047],\n",
       "       [ 194, 1065],\n",
       "       [ 195, 1050],\n",
       "       [ 196,   58],\n",
       "       [ 197,   43],\n",
       "       [ 198, 1067],\n",
       "       [ 200,   33],\n",
       "       [ 201,   21],\n",
       "       [ 202, 1040],\n",
       "       [ 203, 1055],\n",
       "       [ 204,   12],\n",
       "       [ 207,   37],\n",
       "       [ 208, 1052],\n",
       "       [ 209,   57],\n",
       "       [ 210, 1085],\n",
       "       [ 211,   58],\n",
       "       [ 212, 1080],\n",
       "       [ 213, 1083],\n",
       "       [ 214,   82],\n",
       "       [ 215,   50],\n",
       "       [ 216,   49],\n",
       "       [ 217,   65],\n",
       "       [ 219,   65],\n",
       "       [ 220,   73],\n",
       "       [ 221,   11],\n",
       "       [ 222, 1055],\n",
       "       [ 223, 1049],\n",
       "       [ 225,   61],\n",
       "       [ 226,   29],\n",
       "       [ 227,   32],\n",
       "       [ 228,   83],\n",
       "       [ 229,   27],\n",
       "       [ 230,   22],\n",
       "       [ 231,   22],\n",
       "       [ 232,   21],\n",
       "       [ 233, 1055],\n",
       "       [ 234,   69],\n",
       "       [ 235, 1087],\n",
       "       [ 237, 1087],\n",
       "       [ 238, 1053],\n",
       "       [ 240,   45],\n",
       "       [ 241,   12],\n",
       "       [ 242,   21],\n",
       "       [ 244,   34],\n",
       "       [ 245, 1088],\n",
       "       [ 246, 1039],\n",
       "       [ 247, 1040],\n",
       "       [ 254, 1089],\n",
       "       [ 255,   68],\n",
       "       [ 256,   11],\n",
       "       [ 257, 1096],\n",
       "       [ 259,   30],\n",
       "       [ 260,   30],\n",
       "       [ 261, 1044],\n",
       "       [ 262, 1094],\n",
       "       [ 263, 1085],\n",
       "       [ 264,   56],\n",
       "       [ 265,   17],\n",
       "       [ 267,    4],\n",
       "       [ 268,   56],\n",
       "       [ 269,   56],\n",
       "       [ 271,   49],\n",
       "       [ 272,   51],\n",
       "       [ 273, 1044],\n",
       "       [ 274,   69],\n",
       "       [ 275,   17],\n",
       "       [ 276,   37],\n",
       "       [ 277,   88],\n",
       "       [ 278,   20],\n",
       "       [ 279,   43],\n",
       "       [ 280, 1071],\n",
       "       [ 282,   60],\n",
       "       [ 283,   60],\n",
       "       [ 284,   44],\n",
       "       [ 285, 1049],\n",
       "       [ 286,   79],\n",
       "       [ 287,   88],\n",
       "       [ 288, 1055],\n",
       "       [ 289, 1044],\n",
       "       [ 291,   60],\n",
       "       [ 292,   74],\n",
       "       [ 293, 1096],\n",
       "       [ 297, 1041],\n",
       "       [ 298, 1082],\n",
       "       [ 299,    5],\n",
       "       [ 300,   46]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = os.path.join(divided_data_path,'label_table_train.csv')\n",
    "div_label_map = np.loadtxt(label_file,delimiter=',',dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_lhs = div_label_map[:, 0]\n",
    "lhs = label_map[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros((len(div_label_map), 1175))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044\n",
      "14\n",
      "1078\n",
      "63\n",
      "11\n",
      "39\n",
      "1050\n",
      "3\n",
      "37\n",
      "37\n",
      "14\n",
      "14\n",
      "1056\n",
      "1064\n",
      "3\n",
      "60\n",
      "3\n",
      "3\n",
      "41\n",
      "33\n",
      "42\n",
      "3\n",
      "48\n",
      "1069\n",
      "8\n",
      "31\n",
      "1059\n",
      "19\n",
      "1081\n",
      "29\n",
      "22\n",
      "34\n",
      "38\n",
      "9\n",
      "9\n",
      "1059\n",
      "8\n",
      "1057\n",
      "863\n",
      "27\n",
      "42\n",
      "1059\n",
      "1071\n",
      "1077\n",
      "1064\n",
      "53\n",
      "1\n",
      "3\n",
      "45\n",
      "4\n",
      "20\n",
      "1\n",
      "1059\n",
      "5\n",
      "1\n",
      "50\n",
      "69\n",
      "29\n",
      "47\n",
      "1079\n",
      "1072\n",
      "69\n",
      "7\n",
      "1060\n",
      "36\n",
      "49\n",
      "22\n",
      "22\n",
      "14\n",
      "51\n",
      "58\n",
      "24\n",
      "49\n",
      "16\n",
      "64\n",
      "64\n",
      "1052\n",
      "1058\n",
      "50\n",
      "49\n",
      "20\n",
      "1046\n",
      "1091\n",
      "49\n",
      "5\n",
      "37\n",
      "1049\n",
      "23\n",
      "71\n",
      "41\n",
      "1050\n",
      "14\n",
      "1068\n",
      "66\n",
      "1041\n",
      "1050\n",
      "13\n",
      "13\n",
      "1062\n",
      "56\n",
      "62\n",
      "48\n",
      "57\n",
      "7\n",
      "2\n",
      "1068\n",
      "54\n",
      "1053\n",
      "21\n",
      "2\n",
      "1074\n",
      "15\n",
      "1075\n",
      "32\n",
      "1047\n",
      "1071\n",
      "1042\n",
      "1042\n",
      "10\n",
      "57\n",
      "28\n",
      "17\n",
      "43\n",
      "24\n",
      "73\n",
      "47\n",
      "5\n",
      "5\n",
      "11\n",
      "30\n",
      "1070\n",
      "57\n",
      "63\n",
      "1080\n",
      "1073\n",
      "14\n",
      "8\n",
      "1071\n",
      "37\n",
      "1076\n",
      "1080\n",
      "35\n",
      "1055\n",
      "79\n",
      "39\n",
      "48\n",
      "1053\n",
      "33\n",
      "68\n",
      "64\n",
      "10\n",
      "52\n",
      "77\n",
      "1080\n",
      "1047\n",
      "1065\n",
      "1050\n",
      "58\n",
      "43\n",
      "1067\n",
      "33\n",
      "21\n",
      "1040\n",
      "1055\n",
      "12\n",
      "37\n",
      "1052\n",
      "57\n",
      "1085\n",
      "58\n",
      "1080\n",
      "1083\n",
      "82\n",
      "50\n",
      "49\n",
      "65\n",
      "65\n",
      "73\n",
      "11\n",
      "1055\n",
      "1049\n",
      "61\n",
      "29\n",
      "32\n",
      "83\n",
      "27\n",
      "22\n",
      "22\n",
      "21\n",
      "1055\n",
      "69\n",
      "1087\n",
      "1087\n",
      "1053\n",
      "45\n",
      "12\n",
      "21\n",
      "34\n",
      "1088\n",
      "1039\n",
      "1040\n",
      "1089\n",
      "68\n",
      "11\n",
      "1096\n",
      "30\n",
      "30\n",
      "1044\n",
      "1094\n",
      "1085\n",
      "56\n",
      "17\n",
      "4\n",
      "56\n",
      "56\n",
      "49\n",
      "51\n",
      "1044\n",
      "69\n",
      "17\n",
      "37\n",
      "88\n",
      "20\n",
      "43\n",
      "1071\n",
      "60\n",
      "60\n",
      "44\n",
      "1049\n",
      "79\n",
      "88\n",
      "1055\n",
      "1044\n",
      "60\n",
      "74\n",
      "1096\n",
      "1041\n",
      "1082\n",
      "5\n",
      "46\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_label_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist_vec = np.zeros((387, 2350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIstance from upper vectors\n",
    "du = l2_dist_vec.reshape(-1, int(l2_dist_vec.shape[1]/2), 2)[:, :, 0]\n",
    "dl = l2_dist_vec.reshape(-1, int(l2_dist_vec.shape[1]/2), 2)[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(np.array([1,2,3]), np.array([1,3,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   4   5   6   7   8   9  10  11  12  13  14  15  17  19  20  21\n",
      "  22  23  24  25  27  28  29  30  31  32  34  36  37  38  39  41  43  45\n",
      "  46  48  49  53  56  57  58  59  62  63  64  66  67  68  69  70  71  72\n",
      "  73  74  76  77  78  79  80  81  82  83  84  87  89  90  91  92  93  94\n",
      "  95  97  98  99 100 101 103 104 105 107 108 109 110 111 113 114 115 116\n",
      " 117 118 119 121 122 123 124 125 127 128 129 130 131 132 133 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 148 149 150 151 156 159 161 162 164\n",
      " 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182\n",
      " 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 200 201\n",
      " 202 203 204 207 208 209 210 211 212 213 214 215 216 217 219 220 221 222\n",
      " 223 225 226 227 228 229 230 231 232 233 234 235 237 238 240 241 242 244\n",
      " 245 246 247 254 255 256 257 259 260 261 262 263 264 265 267 268 269 271\n",
      " 272 273 274 275 276 277 278 279 280 282 283 284 285 286 287 288 289 291\n",
      " 292 293 297 298 299 300]\n"
     ]
    }
   ],
   "source": [
    "print(lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   3   4   7   8   9  10  11  12  13  15  17  18  19  21  22  23  24\n",
      "  25  27  29  33  34  37  39  40  41  43  44  45  47  49  50  53  54  55\n",
      "  56  57  59  60  61  62  63  67  71  72  73  74  75  76  77  78  81  85\n",
      "  89  90  91  92  95  96  97  98 105 106 111 112 113 115 116 117 118 123\n",
      " 125 126 127 131 133 134 135 136 137 138 139 140 141 143 144 145 147 148\n",
      " 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168\n",
      " 173 174 177 178 179 180 181 183 184 185 186 187 188 189 190 193 194 195\n",
      " 197 199 200 201 205 206 207 208 209 210 213 214 215 216 217 219 220 221\n",
      " 222 225 226 227 228 229 230 231 232 233 234 235 237 238 241 243 244 245\n",
      " 247 248 249 250 253 254 255 257 258 259 261 262 263 264 265 266 271 272\n",
      " 273 274 275 277 278 279 281 282 283 284 285 286 287 288 289 291 292 293\n",
      " 295 296 297 299 301 311 312 317 318 321 322 323 324 327 328 329 330 331\n",
      " 332 333 334 335 336 337 339 340 341 342 343 344 345 347 349 350 351 353\n",
      " 355 356 357 358 359 360 361 363 364 365 366 367 368 369 371 372 373 374\n",
      " 375 377 378 379 381 382 383 384 385 387 389 390 391 393 394 395 399 400\n",
      " 401 403 404 405 407 408 413 414 415 417 419 421 423 424 425 426 427 428\n",
      " 429 430 431 432 433 434 437 438 439 440 441 442 443 444 445 449 451 452\n",
      " 453 455 457 458 459 461 463 464 465 466 467 468 469 470 473 475 479 481\n",
      " 483 487 489 490 491 493 494 507 509 510 511 513 517 518 519 521 523 525\n",
      " 527 529 533 535 537 538 541 542 543 545 546 547 548 549 551 553 554 555\n",
      " 557 558 559 560 563 565 567 569 570 571 573 575 576 577 578 581 582 583\n",
      " 584 585 586 593 595 596 597 599 600]\n"
     ]
    }
   ],
   "source": [
    "print(div_lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "layer_id = 5\n",
    "model = models.resnet50(pretrained=True)\n",
    "modules = list(model.children())[:layer_id] \n",
    "net_base = nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (3): Bottleneck(\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 5.7859e-03]],\n",
      "\n",
      "         [[ 1.3108e-03]],\n",
      "\n",
      "         [[-4.1067e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2579e-03]],\n",
      "\n",
      "         [[-4.1070e-02]],\n",
      "\n",
      "         [[-3.8527e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9597e-03]],\n",
      "\n",
      "         [[-1.0637e-02]],\n",
      "\n",
      "         [[ 1.8890e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8657e-03]],\n",
      "\n",
      "         [[-1.1662e-01]],\n",
      "\n",
      "         [[ 7.1150e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3912e-02]],\n",
      "\n",
      "         [[ 1.8223e-03]],\n",
      "\n",
      "         [[ 2.2519e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2903e-02]],\n",
      "\n",
      "         [[-1.1148e-02]],\n",
      "\n",
      "         [[ 7.2517e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.5342e-03]],\n",
      "\n",
      "         [[-3.2014e-03]],\n",
      "\n",
      "         [[-1.0234e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2434e-02]],\n",
      "\n",
      "         [[-1.1588e-02]],\n",
      "\n",
      "         [[ 1.7599e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4654e-04]],\n",
      "\n",
      "         [[ 5.1545e-03]],\n",
      "\n",
      "         [[-2.1940e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4156e-02]],\n",
      "\n",
      "         [[ 6.5771e-02]],\n",
      "\n",
      "         [[-2.3287e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4907e-03]],\n",
      "\n",
      "         [[-7.4796e-05]],\n",
      "\n",
      "         [[-3.3184e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.5518e-03]],\n",
      "\n",
      "         [[ 2.8951e-02]],\n",
      "\n",
      "         [[-1.3137e-02]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1913, 0.1692, 0.0998, 0.1557, 0.2209, 0.2088, 0.1592, 0.1858, 0.1681,\n",
      "        0.1715, 0.2173, 0.1619, 0.1758, 0.2133, 0.2372, 0.1801, 0.2278, 0.1665,\n",
      "        0.1719, 0.1989, 0.1980, 0.1442, 0.1775, 0.2147, 0.1963, 0.1785, 0.1716,\n",
      "        0.1923, 0.1763, 0.2147, 0.1436, 0.1808, 0.1411, 0.2095, 0.1432, 0.2235,\n",
      "        0.1475, 0.2037, 0.1705, 0.1889, 0.1268, 0.2000, 0.2031, 0.1841, 0.1522,\n",
      "        0.1639, 0.2384, 0.1928, 0.1385, 0.1841, 0.1849, 0.1573, 0.2080, 0.1951,\n",
      "        0.2446, 0.1780, 0.1835, 0.1956, 0.1273, 0.2016, 0.1753, 0.1431, 0.2104,\n",
      "        0.1973], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0211, -0.0407, -0.0112, -0.1323, -0.1030, -0.0420, -0.0627,  0.0480,\n",
      "         0.0803,  0.1414, -0.1111, -0.1918,  0.0786, -0.0938, -0.1518,  0.0853,\n",
      "        -0.1570,  0.1497,  0.0868, -0.0677, -0.0525,  0.1388,  0.0777, -0.0986,\n",
      "         0.0222,  0.0800,  0.0634,  0.0124, -0.0755, -0.1144,  0.0747, -0.0626,\n",
      "         0.1637, -0.0787,  0.1791, -0.0868,  0.1491, -0.0757,  0.0105, -0.1133,\n",
      "        -0.0680,  0.0583, -0.0410, -0.0515,  0.0492, -0.0792, -0.1330, -0.0540,\n",
      "         0.0605, -0.1405, -0.0211,  0.1586, -0.1310, -0.0853, -0.1872,  0.0526,\n",
      "        -0.0925, -0.0578,  0.0782, -0.1039, -0.0210,  0.0612, -0.1123, -0.0781],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 3.3096e-02, -2.2837e-03, -2.6060e-02],\n",
      "          [-1.8888e-03, -1.4137e-02, -7.5973e-03],\n",
      "          [-4.9556e-02,  2.8547e-02, -1.2019e-02]],\n",
      "\n",
      "         [[ 2.0762e-02, -6.0752e-02,  1.7711e-02],\n",
      "          [ 2.2331e-02, -5.3168e-02,  2.7273e-02],\n",
      "          [-1.8588e-02,  7.2604e-03, -4.4545e-03]],\n",
      "\n",
      "         [[ 1.1293e-02,  4.2911e-03,  2.0791e-02],\n",
      "          [-2.3401e-03, -1.7693e-02,  1.8178e-02],\n",
      "          [-5.9822e-03, -9.6152e-03,  8.1386e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3661e-02, -1.2209e-02, -4.6657e-03],\n",
      "          [-3.2961e-03, -3.7944e-03, -2.1736e-02],\n",
      "          [-2.4662e-02,  2.3986e-02, -1.5785e-02]],\n",
      "\n",
      "         [[-4.2326e-02,  5.5694e-03,  1.0661e-02],\n",
      "          [-4.7409e-02,  3.7776e-02,  2.1256e-02],\n",
      "          [-9.4837e-03,  1.1733e-02, -6.1717e-03]],\n",
      "\n",
      "         [[ 3.1075e-03, -7.9047e-03, -2.5325e-02],\n",
      "          [ 8.5359e-03, -6.7326e-03, -1.2789e-02],\n",
      "          [ 7.2580e-03, -1.6795e-02, -7.6375e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1006e-02, -1.9891e-02, -2.5320e-02],\n",
      "          [-3.3499e-04,  1.9618e-02, -2.0495e-02],\n",
      "          [ 4.6272e-02,  7.7210e-02, -5.5360e-02]],\n",
      "\n",
      "         [[-3.7223e-02,  6.7949e-02, -3.3836e-02],\n",
      "          [-5.4784e-02,  6.3341e-02, -3.2365e-02],\n",
      "          [-5.3404e-03, -1.1135e-02, -7.8994e-04]],\n",
      "\n",
      "         [[ 2.9878e-02, -5.3996e-03,  9.8225e-03],\n",
      "          [-3.4435e-03,  1.1870e-03, -4.5666e-03],\n",
      "          [-5.3928e-03, -9.0694e-03,  3.1196e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8036e-02,  2.4209e-02,  7.9403e-03],\n",
      "          [-8.6619e-03,  2.1570e-02, -6.4812e-03],\n",
      "          [-2.2654e-02,  8.9033e-03,  2.2195e-02]],\n",
      "\n",
      "         [[ 6.1954e-03, -1.9543e-02, -1.2755e-02],\n",
      "          [ 1.8484e-02, -1.3425e-02,  2.4133e-05],\n",
      "          [ 1.7827e-03, -5.4650e-03,  3.1103e-02]],\n",
      "\n",
      "         [[-1.4821e-02,  1.6666e-02, -3.1383e-02],\n",
      "          [-9.5354e-05,  2.7465e-02,  2.4956e-02],\n",
      "          [ 7.7412e-03,  2.5979e-03, -2.1601e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4079e-02,  8.0381e-03, -1.7125e-02],\n",
      "          [ 3.8214e-03, -2.4952e-02, -2.6993e-02],\n",
      "          [ 2.8850e-02,  1.9032e-02, -8.6727e-03]],\n",
      "\n",
      "         [[ 8.9605e-03,  1.1186e-02,  2.7754e-02],\n",
      "          [ 3.4283e-03, -6.6164e-02,  2.5678e-02],\n",
      "          [ 3.7452e-02, -2.1241e-02, -2.8383e-02]],\n",
      "\n",
      "         [[ 1.2442e-02,  5.2476e-03, -5.9283e-03],\n",
      "          [ 1.4631e-02, -1.2374e-02, -2.8127e-03],\n",
      "          [-8.1462e-04, -2.5496e-03, -6.6706e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4014e-02,  2.1514e-02,  5.0287e-02],\n",
      "          [-6.9800e-02, -8.5586e-03,  2.6910e-02],\n",
      "          [-4.7790e-02, -6.6275e-02,  3.5433e-02]],\n",
      "\n",
      "         [[-1.2001e-03, -2.2680e-02, -7.8468e-03],\n",
      "          [-3.3417e-02,  2.9589e-02, -8.3864e-02],\n",
      "          [-1.2242e-02,  2.2470e-02,  8.2582e-03]],\n",
      "\n",
      "         [[-1.6228e-03,  1.9872e-02, -5.9169e-03],\n",
      "          [ 9.8616e-03, -4.3809e-03,  1.3927e-02],\n",
      "          [-5.0480e-03,  2.1110e-02, -2.3370e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.9515e-02, -2.5277e-03,  2.3704e-03],\n",
      "          [-2.5449e-02,  2.5781e-03,  1.3212e-02],\n",
      "          [-2.8367e-02,  6.1904e-03, -7.1778e-04]],\n",
      "\n",
      "         [[-1.6230e-03, -1.3667e-02,  1.6481e-02],\n",
      "          [-7.6718e-03, -3.8440e-02,  4.1870e-02],\n",
      "          [-8.3919e-04, -2.0845e-02,  8.6331e-03]],\n",
      "\n",
      "         [[ 2.7622e-02,  9.3908e-03,  1.2196e-02],\n",
      "          [ 2.0812e-02,  2.6994e-03, -4.2113e-03],\n",
      "          [ 2.7357e-02,  7.6224e-04, -8.0598e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1468e-02, -2.5943e-02,  2.7411e-02],\n",
      "          [-6.6122e-02, -4.1655e-02,  5.9899e-02],\n",
      "          [-6.1420e-02,  2.5395e-02,  3.8950e-02]],\n",
      "\n",
      "         [[ 6.2085e-02,  5.7126e-03,  8.0286e-05],\n",
      "          [-1.9108e-02, -3.2557e-02, -3.4181e-02],\n",
      "          [-2.2809e-02, -9.4224e-03, -1.4776e-02]],\n",
      "\n",
      "         [[-2.6983e-02, -2.4507e-02, -1.3865e-02],\n",
      "          [-4.2552e-02, -3.6843e-02,  6.1647e-02],\n",
      "          [-3.8629e-02, -2.1726e-03,  4.2447e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4762e-03, -1.5865e-02,  2.5887e-02],\n",
      "          [ 2.6152e-02, -1.9164e-02, -6.5627e-03],\n",
      "          [-4.7026e-05, -1.0471e-02, -1.3037e-03]],\n",
      "\n",
      "         [[-4.9933e-03,  1.1487e-02, -3.9681e-02],\n",
      "          [-1.2797e-02,  1.7415e-02, -2.6448e-02],\n",
      "          [ 3.2297e-02,  1.2037e-02, -1.5810e-02]],\n",
      "\n",
      "         [[ 3.1153e-02,  4.1138e-03,  1.1098e-02],\n",
      "          [-2.8878e-03, -4.0853e-03, -4.8585e-03],\n",
      "          [ 4.2662e-03, -5.7329e-03,  7.8327e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5365e-02,  1.6538e-02,  5.1379e-02],\n",
      "          [-3.9035e-02,  3.4860e-02,  1.0149e-02],\n",
      "          [-4.4507e-02,  3.3185e-02, -2.4550e-02]],\n",
      "\n",
      "         [[-2.4078e-02, -1.9366e-02, -1.0191e-02],\n",
      "          [-1.6126e-02,  1.9683e-03,  5.2968e-02],\n",
      "          [-1.1998e-03,  2.4451e-02,  6.5782e-03]],\n",
      "\n",
      "         [[-5.2594e-03, -2.8607e-03,  2.9125e-02],\n",
      "          [ 1.5266e-02,  6.4225e-03, -9.4151e-03],\n",
      "          [ 3.6973e-02, -5.3924e-04, -2.3406e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4780e-03,  1.8678e-02,  4.8434e-03],\n",
      "          [ 2.7248e-02, -3.3991e-02,  1.4853e-02],\n",
      "          [-4.3406e-02,  1.9014e-02, -1.0946e-02]],\n",
      "\n",
      "         [[ 3.8813e-03, -1.0640e-02, -1.2859e-02],\n",
      "          [ 1.4223e-02,  1.7025e-02,  1.5361e-02],\n",
      "          [-2.6170e-02, -1.2333e-02,  3.2009e-02]],\n",
      "\n",
      "         [[ 1.1578e-02,  1.5274e-04,  3.5564e-03],\n",
      "          [ 7.9022e-03,  2.6997e-02,  9.6522e-03],\n",
      "          [-1.3545e-03, -2.9908e-04,  1.0236e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0883e-02, -1.2606e-02,  5.2883e-03],\n",
      "          [ 1.9850e-02, -3.1524e-02, -4.9819e-02],\n",
      "          [ 1.5679e-02,  4.7178e-02, -2.1810e-02]],\n",
      "\n",
      "         [[-1.1884e-02, -1.6430e-02,  4.3056e-03],\n",
      "          [ 2.1827e-02, -3.3460e-02, -1.5285e-02],\n",
      "          [-1.9582e-04,  3.6705e-02, -1.6792e-02]],\n",
      "\n",
      "         [[-1.6154e-02,  1.7052e-02,  1.9213e-03],\n",
      "          [-1.3728e-02,  2.2707e-02,  7.7133e-03],\n",
      "          [ 2.4167e-02, -9.8935e-03, -8.9031e-03]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2164, 0.2510, 0.2231, 0.2292, 0.2206, 0.2179, 0.2162, 0.1634, 0.2093,\n",
      "        0.2222, 0.2535, 0.3154, 0.2342, 0.2426, 0.2290, 0.2137, 0.2216, 0.1808,\n",
      "        0.2402, 0.2401, 0.2296, 0.2416, 0.2316, 0.2086, 0.2435, 0.2377, 0.2285,\n",
      "        0.2185, 0.2242, 0.2128, 0.2328, 0.2420, 0.1663, 0.2489, 0.1979, 0.2088,\n",
      "        0.2402, 0.1934, 0.1159, 0.2452, 0.2377, 0.1765, 0.2250, 0.1855, 0.2238,\n",
      "        0.2285, 0.2402, 0.2207, 0.2157, 0.2389, 0.2259, 0.2190, 0.2020, 0.2269,\n",
      "        0.2276, 0.2248, 0.2533, 0.1996, 0.2053, 0.1992, 0.2117, 0.2513, 0.2136,\n",
      "        0.2317], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0306, -0.0923, -0.0414, -0.0653, -0.1028, -0.0986, -0.0136, -0.0025,\n",
      "        -0.1152, -0.0291, -0.0657, -0.3410, -0.0687, -0.0501, -0.0541, -0.0482,\n",
      "        -0.0685,  0.0415, -0.0591, -0.0672, -0.0274, -0.1126, -0.0099, -0.0306,\n",
      "        -0.1327, -0.0547, -0.0480, -0.0265, -0.0448, -0.0258, -0.0761, -0.1036,\n",
      "         0.0966, -0.0771,  0.0057, -0.0256, -0.1545,  0.1036,  0.2601, -0.1233,\n",
      "        -0.0618,  0.0686, -0.0530,  0.0247, -0.0409, -0.0814, -0.0808, -0.0434,\n",
      "        -0.0131, -0.0899, -0.0204, -0.0730, -0.0149, -0.0785, -0.0759, -0.1011,\n",
      "        -0.0613, -0.1066,  0.0035,  0.0221, -0.0881, -0.0364, -0.0522, -0.0728],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0043]],\n",
      "\n",
      "         [[-0.0028]],\n",
      "\n",
      "         [[-0.0020]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0021]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         [[ 0.0023]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0011]],\n",
      "\n",
      "         [[ 0.0030]],\n",
      "\n",
      "         [[ 0.0068]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0025]],\n",
      "\n",
      "         [[ 0.0081]],\n",
      "\n",
      "         [[-0.0066]]],\n",
      "\n",
      "\n",
      "        [[[-0.0199]],\n",
      "\n",
      "         [[-0.0104]],\n",
      "\n",
      "         [[-0.0676]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0245]],\n",
      "\n",
      "         [[-0.0060]],\n",
      "\n",
      "         [[-0.1256]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0013]],\n",
      "\n",
      "         [[ 0.0002]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0007]],\n",
      "\n",
      "         [[ 0.0084]],\n",
      "\n",
      "         [[ 0.0039]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0002]],\n",
      "\n",
      "         [[ 0.0035]],\n",
      "\n",
      "         [[-0.0059]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         [[-0.0049]],\n",
      "\n",
      "         [[-0.0030]]],\n",
      "\n",
      "\n",
      "        [[[-0.0474]],\n",
      "\n",
      "         [[-0.0324]],\n",
      "\n",
      "         [[ 0.0087]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0097]],\n",
      "\n",
      "         [[-0.0294]],\n",
      "\n",
      "         [[-0.0360]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.5923e-03,  3.9254e-03,  2.4249e-01,  1.3147e-02,  2.0007e-01,\n",
      "        -3.2185e-04,  1.1565e-01,  4.6914e-02, -1.5021e-03, -2.1276e-02,\n",
      "        -2.6685e-03,  1.4753e-01,  2.1443e-01, -6.9608e-03,  1.1943e-01,\n",
      "         1.2552e-01,  4.0872e-03,  7.9870e-02, -4.8085e-04, -4.8666e-04,\n",
      "         1.2917e-01,  7.9297e-02,  1.5621e-01,  1.0811e-01,  8.1673e-02,\n",
      "         2.2446e-01,  1.6008e-03,  5.1752e-02, -2.1425e-03, -4.1347e-03,\n",
      "         5.5874e-03,  1.6457e-03, -7.5116e-03,  5.5340e-02,  1.3223e-01,\n",
      "        -4.4711e-03,  2.2457e-03, -4.7519e-03, -3.3598e-03,  2.3241e-03,\n",
      "         3.5016e-01,  1.6626e-02,  1.3429e-01,  8.7274e-03, -2.2221e-03,\n",
      "         2.1726e-01,  3.8173e-04,  1.8875e-01,  2.4498e-01,  1.9210e-01,\n",
      "        -1.5552e-02,  4.3431e-02,  2.3153e-01,  1.8777e-01,  5.6176e-03,\n",
      "         6.8458e-03,  9.6181e-04,  1.2022e-01,  1.5761e-03,  3.8495e-03,\n",
      "         1.6509e-02,  3.7691e-03, -3.7044e-03,  3.4143e-03,  3.7547e-01,\n",
      "         9.6327e-04,  2.0730e-01,  1.3995e-02,  6.1402e-02,  3.6116e-04,\n",
      "         1.4752e-01,  2.5778e-01,  6.4280e-02, -5.6550e-03, -2.9041e-03,\n",
      "         9.2023e-02,  1.2709e-01,  2.0836e-02, -5.7879e-03,  5.0520e-02,\n",
      "         9.4376e-04, -6.8810e-03,  4.0449e-03,  2.2498e-01,  1.0739e-01,\n",
      "         1.4813e-01,  1.8075e-01,  2.5015e-01, -3.8219e-03,  2.3577e-01,\n",
      "        -1.6626e-03,  8.5213e-02,  1.0438e-03,  2.7836e-01,  1.4462e-01,\n",
      "         6.2460e-02,  3.3796e-03,  1.4250e-01,  3.7376e-04,  5.0352e-02,\n",
      "         3.2150e-02,  2.7668e-01,  1.3964e-01,  6.0652e-03,  5.9212e-02,\n",
      "         8.5587e-02,  1.2062e-01,  2.2024e-01,  1.6723e-03, -5.6672e-03,\n",
      "        -2.9752e-03,  2.2320e-03,  6.4960e-04,  1.1749e-02,  7.0809e-02,\n",
      "         6.8258e-02,  1.9609e-02,  1.9424e-01,  1.4364e-01, -4.6868e-02,\n",
      "         3.1891e-02, -9.7883e-02,  7.8508e-03,  3.3273e-01, -4.1975e-03,\n",
      "         8.4416e-04,  1.1355e-01,  3.3805e-01,  1.4239e-01,  9.8107e-02,\n",
      "         1.3453e-01,  5.8075e-02,  1.3168e-01,  2.3258e-01,  1.7535e-01,\n",
      "        -1.2962e-02,  1.2742e-01,  1.8458e-01,  1.0246e-02,  1.9722e-01,\n",
      "         1.8699e-01, -4.5020e-03,  4.8174e-02,  1.3220e-01, -3.2639e-04,\n",
      "         2.4005e-03,  1.8434e-02,  4.7764e-02,  4.0037e-02,  1.0904e-01,\n",
      "         5.4055e-04,  1.4809e-01,  1.8626e-01,  1.2066e-01,  2.1117e-04,\n",
      "         1.0883e-01,  2.2160e-03,  1.0662e-01,  6.6964e-03, -3.4917e-04,\n",
      "         1.6360e-03,  5.2486e-02,  4.0103e-04,  7.3373e-03,  1.8499e-01,\n",
      "         7.8452e-04,  1.2660e-01,  5.9067e-03,  4.8742e-02,  2.1743e-01,\n",
      "         6.9027e-02,  2.8614e-03,  1.6751e-01,  2.1230e-01,  1.9725e-01,\n",
      "         1.4877e-01,  6.1662e-02,  1.1902e-03,  1.0716e-01,  1.2783e-01,\n",
      "         2.1050e-01,  8.1410e-03,  6.2906e-02,  7.1060e-02, -2.7128e-03,\n",
      "         1.7258e-01,  2.4634e-05,  7.5922e-02,  1.0812e-02,  1.8710e-03,\n",
      "         8.2368e-03, -8.0845e-04,  3.8778e-03, -3.0493e-02,  1.6607e-01,\n",
      "        -1.6289e-03,  7.1129e-02,  1.6436e-02, -2.9241e-03,  1.7963e-01,\n",
      "         2.4212e-02,  3.2674e-02,  2.1873e-01,  4.7956e-03,  1.9497e-01,\n",
      "         1.4281e-03,  1.5408e-01,  1.0100e-01,  4.6857e-02,  2.2967e-02,\n",
      "         1.2381e-01,  2.1717e-01,  1.2651e-01,  6.1652e-02,  6.2563e-02,\n",
      "         4.2479e-03,  1.7376e-01,  1.4670e-01,  9.9366e-02,  9.4216e-02,\n",
      "        -2.3530e-03,  1.6592e-01,  1.8851e-01,  1.9745e-04,  5.5619e-03,\n",
      "         6.1706e-02, -4.3745e-03,  8.3113e-03,  3.9033e-03,  7.9864e-02,\n",
      "         2.4560e-01, -4.0077e-03,  6.2504e-02,  3.0014e-03, -1.8519e-03,\n",
      "         5.8024e-03,  1.2154e-01, -4.8917e-03,  3.0175e-02,  1.0293e-02,\n",
      "         8.7251e-02,  3.4200e-02, -4.8267e-04, -3.7933e-03,  2.6417e-02,\n",
      "        -5.0796e-03,  2.3757e-01,  1.0215e-01,  1.7780e-01,  1.5232e-01,\n",
      "        -3.5495e-03,  4.1498e-04, -9.2583e-04, -2.6891e-04, -1.3040e-02,\n",
      "         1.7283e-01], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.6992e-03,  5.0382e-03, -5.3581e-03,  1.2441e-02, -8.8081e-02,\n",
      "         4.7532e-04, -2.4655e-02, -4.1756e-02,  3.4699e-03, -2.3479e-02,\n",
      "         6.9927e-03, -1.0782e-01,  5.3510e-02,  5.7055e-03, -8.9744e-02,\n",
      "         5.9679e-02,  5.1555e-03, -4.0477e-02, -6.0349e-02,  2.9654e-03,\n",
      "        -4.9220e-02, -2.9692e-02, -6.3090e-02, -5.9043e-02, -5.8201e-02,\n",
      "        -5.7618e-02,  1.9976e-03,  7.9507e-02,  3.9805e-03,  6.4963e-03,\n",
      "        -1.5410e-02,  1.9556e-03,  4.4848e-03,  2.8314e-03, -6.3766e-03,\n",
      "         4.1988e-03,  9.6905e-03,  8.4190e-03,  2.2747e-03,  3.1662e-03,\n",
      "        -1.8830e-02,  1.6370e-02, -1.2802e-01,  1.2666e-02,  1.6747e-03,\n",
      "         1.7381e-02,  3.8164e-03, -7.1342e-02,  7.3178e-04,  7.7011e-02,\n",
      "         8.1400e-04,  5.1719e-02,  1.3280e-01, -9.5838e-02,  4.5241e-04,\n",
      "         3.5057e-03,  2.7114e-03, -5.7659e-03,  4.5499e-03,  7.1968e-03,\n",
      "         1.9823e-03,  5.0345e-03, -4.8034e-04,  3.3404e-03, -3.3814e-02,\n",
      "         3.5957e-03,  1.5875e-02,  1.9627e-03, -9.2767e-02,  4.3835e-03,\n",
      "        -4.2223e-02,  6.9495e-02, -1.0593e-02,  2.4233e-03,  7.5824e-03,\n",
      "        -6.6293e-03,  1.4546e-01, -5.7654e-02,  1.5647e-03, -5.1676e-02,\n",
      "         3.4277e-03,  1.5668e-03,  9.0013e-03,  5.7906e-02,  5.8805e-02,\n",
      "         9.8467e-02, -5.1271e-02,  6.3085e-02,  6.8982e-03,  1.2536e-01,\n",
      "         2.6876e-03, -7.8096e-02,  3.3555e-03, -1.6889e-02, -1.0709e-01,\n",
      "        -5.2900e-02,  6.5568e-03, -1.6622e-01, -3.1676e-03,  3.8857e-02,\n",
      "        -8.9695e-03,  7.2363e-02, -1.2169e-01,  3.0069e-03, -4.9618e-02,\n",
      "        -6.4907e-02, -2.5070e-02,  1.5951e-01,  9.6958e-04,  6.2200e-03,\n",
      "         6.8251e-04,  2.5500e-03,  3.0048e-03,  8.5628e-03, -1.2875e-01,\n",
      "        -3.1084e-02,  8.1635e-03,  7.6135e-02, -5.5718e-02,  8.2841e-03,\n",
      "        -3.6918e-02, -1.5486e-01, -4.2461e-03,  2.0860e-02,  9.8043e-04,\n",
      "         7.9003e-03, -1.3246e-01, -6.7532e-03,  1.7541e-01, -2.1152e-02,\n",
      "        -1.2872e-01, -4.9117e-02, -2.8269e-02, -6.9213e-02,  1.3988e-01,\n",
      "        -1.0839e-02, -2.1480e-02,  9.0547e-02,  8.3040e-03,  1.1524e-01,\n",
      "         9.4258e-03, -9.1795e-05, -5.4175e-02, -6.9126e-02, -3.6628e-02,\n",
      "         8.4504e-03,  7.6586e-03, -1.5426e-02, -7.0979e-02,  4.2078e-02,\n",
      "         5.1665e-03, -6.9608e-02, -7.6358e-02,  9.2201e-02,  4.1193e-03,\n",
      "        -1.3960e-01,  2.3765e-03, -1.0904e-01,  3.2954e-03,  4.3768e-03,\n",
      "         2.2496e-03, -4.0969e-02,  7.0422e-04,  6.4295e-04, -5.0308e-02,\n",
      "         2.5666e-03, -1.5794e-01,  6.3643e-03, -5.2255e-02, -9.3409e-02,\n",
      "         4.2246e-02,  6.9041e-03, -1.2083e-01, -2.4038e-02, -1.7824e-02,\n",
      "         2.5941e-02, -6.6151e-02,  5.4090e-03, -7.6903e-02, -7.1961e-02,\n",
      "        -8.4716e-02, -5.0294e-03, -6.6614e-02, -1.0553e-01,  2.6018e-03,\n",
      "         1.9690e-01,  3.3359e-03,  6.1511e-02,  1.0994e-02,  4.4189e-03,\n",
      "         6.9681e-03,  4.8677e-03,  4.0604e-03, -2.5730e-02,  8.0124e-02,\n",
      "         2.0603e-03, -6.6625e-02,  3.3132e-03,  2.0055e-03,  6.7946e-03,\n",
      "        -1.0491e-02, -7.7521e-03,  1.2242e-01,  4.5047e-03, -7.1743e-02,\n",
      "         8.5945e-03, -4.8786e-02,  1.5492e-01, -3.0984e-02,  2.5433e-02,\n",
      "        -5.0546e-02,  7.0953e-02, -4.7523e-02,  2.4916e-03, -9.7288e-02,\n",
      "         1.2981e-03, -8.5806e-02, -1.0631e-01, -6.9902e-02, -3.4147e-02,\n",
      "         5.2914e-03, -1.1379e-01,  2.4093e-02,  3.3743e-03,  3.1187e-03,\n",
      "        -6.4556e-02,  3.8068e-03,  2.7139e-03,  4.5545e-03,  6.2054e-03,\n",
      "        -1.2041e-01,  2.6672e-03, -7.7625e-03, -1.7428e-04,  3.6261e-03,\n",
      "         6.1757e-03, -1.6837e-01,  7.0741e-03, -3.0000e-02, -2.4920e-02,\n",
      "        -9.5481e-03,  1.1757e-02,  3.3857e-03,  1.0306e-02, -5.2387e-02,\n",
      "         3.4361e-03,  1.6722e-02, -1.4745e-01,  3.0167e-02, -5.5876e-02,\n",
      "         6.0108e-03,  4.3211e-03,  3.4444e-03,  5.2922e-03,  5.1733e-03,\n",
      "        -1.5416e-01], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net_base[-1][-1].parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.49127409, 0.59324154, 0.43689013, 0.56582177],\n",
       "        [0.47537999, 0.06962565, 0.0249453 , 0.08658383],\n",
       "        [0.34935651, 0.44845262, 0.90303455, 0.50780448]],\n",
       "\n",
       "       [[0.12280073, 0.54399206, 0.03181867, 0.13016012],\n",
       "        [0.77691304, 0.58415058, 0.40649186, 0.16595774],\n",
       "        [0.90659031, 0.68229594, 0.99908489, 0.48462859]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.03053279,  0.07143466, -0.08491675,  0.04401489],\n",
       "        [ 0.3112463 , -0.09450804, -0.13918839, -0.07754986],\n",
       "        [-0.20280553, -0.10370942,  0.35087251, -0.04435756]],\n",
       "\n",
       "       [[-0.08439216,  0.33679917, -0.17537423, -0.07703278],\n",
       "        [ 0.29353474,  0.10077228, -0.07688644, -0.31742057],\n",
       "        [ 0.13844038, -0.08585399,  0.23093495, -0.28352134]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.mean(2).shape)\n",
    "a-a.mean(2)[:,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = torch.tensor(np.zeros((2,3,4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.tensor(np.zeros((2,3,4)))\n",
    "v2 = torch.tensor(np.zeros((2,3,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "den = torch.norm(v1, dim=2)*torch.norm(v2, dim=2) + 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = (v1*v2).sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "den.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.zeros((2,3,4))\n",
    "v2 = np.zeros((2,3,4))\n",
    "den = np.linalg.norm(v1, axis=1)*np.linalg.norm(v2, axis=1) + 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "den.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = list(model.children())[:7] \n",
    "net_base = nn.Sequential(*modules)\n",
    "for param in net_base[-1][-1].parameters():\n",
    "    a  = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in list(net_base[-1][-1].children())[-3:-1]:\n",
    "    layer.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
