{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "miTsY47nfz0G",
    "outputId": "3f1d8dea-ee45-40e8-a98f-910a2f8471b0"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxpU2xoGgu_W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6KZjbT8bhtgO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'img2vec' already exists and is not an empty directory.\n",
      "From https://github.com/anandbhoraskar/img2vec\n",
      " * branch            master     -> FETCH_HEAD\n",
      "Already up-to-date.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/anandbhoraskar/img2vec.git\n",
    "!cd img2vec && git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVxTQz4whwR3"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/drive/My\\ Drive/Sem1/10701/data/FID-300.zip \n",
    "# !unzip /content/drive/My\\ Drive/Sem1/10701/data/CSFID.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1a8clTUgiQ3H"
   },
   "outputs": [],
   "source": [
    "data_path = \"../../data/FID-300/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPIBj71CkI1z"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, 'img2vec')\n",
    "from img2vec_pytorch import Img2Vec\n",
    "import img2vec_pytorch\n",
    "import importlib\n",
    "importlib.reload(img2vec_pytorch)\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5moesp_2mL36"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hW5q9s4Mmb5m"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "label_table = loadmat(os.path.join(data_path, 'label_table.mat'))\n",
    "label_table = label_table['label_table']\n",
    "# print(label_table['label_table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xc39A10WpOhq"
   },
   "outputs": [],
   "source": [
    "references = np.arange(1, 1176)\n",
    "# print(references)\n",
    "\n",
    "test_val = np.arange(1, 301)\n",
    "# print(test_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4w9JOBhetIQA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6RjbrhFqHjr"
   },
   "outputs": [],
   "source": [
    "def file_path(i:int, data:str = 'ref'):\n",
    "  if data == 'ref':\n",
    "    # print('ref')\n",
    "    return data_path+\"/references/\"+\"{:05d}\".format(i)+\".png\"\n",
    "  else:\n",
    "    # print('test')\n",
    "    return data_path+\"/tracks_cropped/\"+\"{:05d}\".format(i)+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eywh6-zpqx9W",
    "outputId": "5a254996-3d17-4e10-89cf-5dc3df982ff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/FID-300//references/00001.png\n",
      "../../data/FID-300//tracks_cropped/00001.jpg\n"
     ]
    }
   ],
   "source": [
    "print(file_path(1, 'ref'))\n",
    "print(file_path(1, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OKpFUNNKsHFB"
   },
   "outputs": [],
   "source": [
    "ref_img_list = []\n",
    "for i in references:\n",
    "  img = Image.open(file_path(i,'ref'))\n",
    "  img = img.convert(\"RGB\")\n",
    "  ref_img_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmsB-ALDsIam"
   },
   "outputs": [],
   "source": [
    "test_img_list = []\n",
    "for i in test_val:\n",
    "  img = Image.open(file_path(i,'test'))\n",
    "  img = img.convert(\"RGB\")\n",
    "  test_img_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7LioWdTkaP6"
   },
   "outputs": [],
   "source": [
    "import img2vec_pytorch\n",
    "import importlib\n",
    "importlib.reload(img2vec_pytorch)\n",
    "img2vec = img2vec_pytorch.Img2Vec(cuda=True, layer_output_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzuNxRQh40Nr"
   },
   "outputs": [],
   "source": [
    "# img2vec.layer_output_size = 2048\n",
    "# print(img2vec.layer_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKfgCCQHuQ-V"
   },
   "outputs": [],
   "source": [
    "ref_vec_list = []\n",
    "test_vec_list = []\n",
    "\n",
    "ref_vec_list = [img2vec.get_vec(img, tensor=True) for img in ref_img_list]\n",
    "test_vec_list = [img2vec.get_vec(img, tensor=True) for img in test_img_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30zPluyi5HeH"
   },
   "outputs": [],
   "source": [
    "ref_vec_list_np = np.array([np.array(vec) for vec in ref_vec_list])\n",
    "test_vec_list_np = np.array([np.array(vec) for vec in test_vec_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zo_vxAQFuY8G"
   },
   "outputs": [],
   "source": [
    "ref_vec_list_np = ref_vec_list_np.reshape(1175, 2048)\n",
    "test_vec_list_np = test_vec_list_np.reshape(300, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjYZZjBfx5c2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "score = cosine_similarity(test_vec_list_np, ref_vec_list_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTk3yYhK9D56"
   },
   "outputs": [],
   "source": [
    "score_sort = (-score).argsort(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAXI2S4w-u39"
   },
   "outputs": [],
   "source": [
    "pos_array = []\n",
    "for a,b,c in zip(score_sort, score.argmax(1), label_table[:, 1]-1):\n",
    "  pos_array.append(np.where(a==c)[0][0])\n",
    "pos_array = np.array(pos_array)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yDBQQ3aoC6v0",
    "outputId": "119617d8-a3d7-4f84-95c3-0662fb4b8626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5: 22.666666666666668\n"
     ]
    }
   ],
   "source": [
    "t = 5\n",
    "thresh = t*pos_array.shape[0]/100\n",
    "acc = 100*np.sum((pos_array<thresh))/pos_array.shape[0]\n",
    "print(\"top {}: {}\".format(t, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OTXT0JErDsEl",
    "outputId": "9737dc0c-1679-4a6a-87cc-d6ed635bbd9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10: 32.666666666666664\n"
     ]
    }
   ],
   "source": [
    "t = 10\n",
    "thresh = t*pos_array.shape[0]/100\n",
    "acc = 100*np.sum((pos_array<thresh))/pos_array.shape[0]\n",
    "print(\"top {}: {}\".format(t, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0KamUynDwUk"
   },
   "outputs": [],
   "source": [
    "def find_scores(img2vec, layer_output_size=512, return_tensor=False):\n",
    "  if return_tensor:\n",
    "    ref_vec_list = np.array([img2vec.get_vec(img).mean(1).flatten().numpy() for img in ref_img_list])\n",
    "    test_vec_list = np.array([img2vec.get_vec(img).mean(1).flatten().numpy() for img in test_img_list])\n",
    "  else:\n",
    "    ref_vec_list = np.array([img2vec.get_vec(img) for img in ref_img_list])\n",
    "    test_vec_list = np.array([img2vec.get_vec(img) for img in test_img_list])\n",
    "\n",
    "  ref_vec_list = ref_vec_list.reshape(1175, layer_output_size)\n",
    "  test_vec_list = test_vec_list.reshape(300, layer_output_size)\n",
    "\n",
    "  # test_vec_list = (test_vec_list-test_vec_list.mean(1)[:, None])/test_vec_list.std(1)[:, None]\n",
    "  # ref_vec_list = (ref_vec_list-ref_vec_list.mean(1)[:, None])/ref_vec_list.std(1)[:, None]\n",
    "  score = cosine_similarity(test_vec_list, ref_vec_list)\n",
    "  score_sort = (-score).argsort(1)\n",
    "\n",
    "  pos_array = []\n",
    "  for a,b,c in zip(score_sort, score.argmax(1), label_table[:, 1]-1):\n",
    "    pos_array.append(np.where(a==c)[0][0])\n",
    "  pos_array = np.array(pos_array)\n",
    "\n",
    "  t = 5\n",
    "  thresh = t*pos_array.shape[0]/100\n",
    "  acc = 100*np.sum((pos_array<thresh))/pos_array.shape[0]\n",
    "  print(\"top {}: {}\".format(t, acc))\n",
    "\n",
    "  t = 10\n",
    "  thresh = t*pos_array.shape[0]/100\n",
    "  acc = 100*np.sum((pos_array<thresh))/pos_array.shape[0]\n",
    "  print(\"top {}: {}\".format(t, acc))\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkK06M9SRe6G"
   },
   "outputs": [],
   "source": [
    "def mcncc(v1, v2):\n",
    "  den = np.linalg.norm(v1, axis=1)*np.linalg.norm(v2, axis=1) + 1e-12\n",
    "  num = (v1*v2).sum(axis=1)\n",
    "  return (num/den).sum()\n",
    "\n",
    "# def mcncc_all(test_vec_list, ref_vec_list):\n",
    "#     den = np.linalg.norm(test_vec_list, axis=2)*np.linalg.norm(v2, axis=2) + 1e-12\n",
    "#     num = (v1*v2).sum(axis=1)\n",
    "    \n",
    "\n",
    "def find_scores_mcncc(img2vec, layer_output_size=512, return_tensor=False):\n",
    "  ref_vec_list = np.array([img2vec.get_vec(img).numpy() for img in ref_img_list])\n",
    "  test_vec_list = np.array([img2vec.get_vec(img).numpy() for img in test_img_list])\n",
    "\n",
    "  ref_vec_list = ref_vec_list.reshape(ref_vec_list.shape[0], ref_vec_list.shape[2],ref_vec_list.shape[3]*ref_vec_list.shape[4])\n",
    "  test_vec_list = test_vec_list.reshape(test_vec_list.shape[0], test_vec_list.shape[2], test_vec_list.shape[3]*test_vec_list.shape[4])\n",
    "\n",
    "  test_vec_list = (test_vec_list-test_vec_list.mean(1)[:, None])/test_vec_list.std(1)[:, None]\n",
    "  ref_vec_list = (ref_vec_list-ref_vec_list.mean(1)[:, None])/ref_vec_list.std(1)[:, None]\n",
    "    \n",
    "  print(\"computing score\")\n",
    "#   score = mcncc_all(test_vec_list, ref_vec_list)\n",
    "  score = np.zeros((test_vec_list.shape[0], ref_vec_list.shape[0]))\n",
    "  for i, v1 in enumerate(test_vec_list):\n",
    "    print(i)\n",
    "    for j, v2 in enumerate(ref_vec_list):\n",
    "      score[i, j] = mcncc(v1, v2)\n",
    "\n",
    "  score_sort = (-score).argsort(1)\n",
    "\n",
    "  pos_array = []\n",
    "  for a,b,c in zip(score_sort, score.argmax(1), label_table[:, 1]-1):\n",
    "    pos_array.append(np.where(a==c)[0][0])\n",
    "  pos_array = np.array(pos_array)\n",
    "\n",
    "  t = 5\n",
    "  thresh = t*pos_array.shape[0]/100\n",
    "  acc = 100*np.sum((pos_array<thresh))/pos_array.shape[0]\n",
    "  print(\"top {}: {}\".format(t, acc))\n",
    "\n",
    "  t = 10\n",
    "  thresh = t*pos_array.shape[0]/100\n",
    "  acc = 100*np.sum((pos_array<thresh))/pos_array.shape[0]\n",
    "  print(\"top {}: {}\".format(t, acc))\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best performing\n",
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer3', layer_output_size=256, \n",
    "#     channels=14, return_embedding=True)\n",
    "# score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "m-SgIflpWIZH",
    "outputId": "b686e0a0-d60a-4136-f8f3-afbfc5a65e39"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(cuda=True, layer_output_size=2048, centre_crop=True)\n",
    "# print(img2vec.layer_output_size)\n",
    "# score_layer4 = find_scores(img2vec)\n",
    "\n",
    "# # Cos sim (centre crop)\n",
    "# # top 5: 24.666666666666668\n",
    "# # top 10: 35.0\n",
    "\n",
    "\n",
    "# # Normalize:\n",
    "# # top 5: 22.333333333333332\n",
    "# # top 10: 30.333333333333332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nD3YZhFoWNvV",
    "outputId": "8f1006a3-5669-4ee7-9357-b4a1999370e0"
   },
   "outputs": [],
   "source": [
    "# img2vec_layer3 = img2vec_pytorch.Img2Vec(cuda=True, layer='layer3', layer_output_size=1024, centre_crop=True)\n",
    "# score_layer3 = find_scores(img2vec_layer3)\n",
    "\n",
    "# # Cos\n",
    "# # top 5: 6.0\n",
    "# # top 10: 8.666666666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KfgXXcWPX_Wv",
    "outputId": "e50f2b55-45b1-41d1-935d-b17e94a99d76"
   },
   "outputs": [],
   "source": [
    "# img2vec_layer2 = img2vec_pytorch.Img2Vec(cuda=True, layer='layer2', layer_output_size=512, centre_crop=True)\n",
    "# score_layer2 = find_scores(img2vec_layer2)\n",
    "\n",
    "# # Cos\n",
    "# # top 5: 7.0\n",
    "# # top 10: 11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5Flg9R1mjz4x",
    "outputId": "b740a001-ab08-4673-f569-8b1ae94c30be"
   },
   "outputs": [],
   "source": [
    "# img2vec_layer1 = img2vec_pytorch.Img2Vec(cuda=True, layer='layer1', layer_output_size=256, centre_crop=True)\n",
    "# score_layer1 = find_scores(img2vec_layer1)\n",
    "\n",
    "# #Cos\n",
    "# # top 5: 5.333333333333333\n",
    "# # top 10: 7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "m-SgIflpWIZH",
    "outputId": "b686e0a0-d60a-4136-f8f3-afbfc5a65e39"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(cuda=True, layer_output_size=2048, top_crop=True)\n",
    "# print(img2vec.layer_output_size)\n",
    "# score_layer4 = find_scores(img2vec, 2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nD3YZhFoWNvV",
    "outputId": "8f1006a3-5669-4ee7-9357-b4a1999370e0"
   },
   "outputs": [],
   "source": [
    "# img2vec_layer3 = img2vec_pytorch.Img2Vec(cuda=True, layer='layer3', layer_output_size=1024, top_crop=True)\n",
    "# score_layer3 = find_scores(img2vec_layer3, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KfgXXcWPX_Wv",
    "outputId": "e50f2b55-45b1-41d1-935d-b17e94a99d76"
   },
   "outputs": [],
   "source": [
    "# img2vec_layer2 = img2vec_pytorch.Img2Vec(cuda=True, layer='layer2', layer_output_size=512, top_crop=True)\n",
    "# score_layer2 = find_scores(img2vec_layer2, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5Flg9R1mjz4x",
    "outputId": "b740a001-ab08-4673-f569-8b1ae94c30be",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img2vec_layer1 = img2vec_pytorch.Img2Vec(cuda=True, layer='layer1', layer_output_size=256, top_crop=True)\n",
    "# score_layer1 = find_scores(img2vec_layer1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "m-SgIflpWIZH",
    "outputId": "b686e0a0-d60a-4136-f8f3-afbfc5a65e39"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(cuda=True, layer_output_size=2048)\n",
    "# print(img2vec.layer_output_size)\n",
    "# score_layer4 = find_scores(img2vec, 2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nD3YZhFoWNvV",
    "outputId": "8f1006a3-5669-4ee7-9357-b4a1999370e0"
   },
   "outputs": [],
   "source": [
    "# img2vec_layer3 = img2vec_pytorch.Img2Vec(cuda=True, layer='layer3', layer_output_size=1024)\n",
    "# score_layer3 = find_scores(img2vec_layer3, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KfgXXcWPX_Wv",
    "outputId": "e50f2b55-45b1-41d1-935d-b17e94a99d76"
   },
   "outputs": [],
   "source": [
    "# img2vec_layer2 = img2vec_pytorch.Img2Vec(cuda=True, layer='layer2', layer_output_size=512)\n",
    "# score_layer2 = find_scores(img2vec_layer2, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5Flg9R1mjz4x",
    "outputId": "b740a001-ab08-4673-f569-8b1ae94c30be",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img2vec_layer1 = img2vec_pytorch.Img2Vec(cuda=True, layer='layer1', layer_output_size=256)\n",
    "# score_layer1 = find_scores(img2vec_layer1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dvs-0la5hc5w",
    "outputId": "4a3b83d8-0ffd-4f72-fc34-3450c12f73d5"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer1', layer_output_size=256, \n",
    "#     channels=56, return_embedding=True)\n",
    "# score_layer2_conv = find_scores(img2vec, 3136, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RNXC7nN4oB2B",
    "outputId": "f69198ec-994d-4178-88f9-5a77f548e8cd"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer2', layer_output_size=128, \n",
    "#     channels=28, return_embedding=True)\n",
    "# score_layer2_conv = find_scores(img2vec, 784, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "R_lt-V3So7Zk",
    "outputId": "f67518a6-71a2-4da9-9bd4-6c4a77d0517b"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer3', layer_output_size=256, \n",
    "#     channels=14, return_embedding=True)\n",
    "# score_layer2_conv = find_scores(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "AeoYmHrvpFtC",
    "outputId": "16422562-8643-4be1-e5bc-5f5c05a00c4b"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer4', layer_output_size=512, \n",
    "#     channels=7, return_embedding=True)\n",
    "# score_layer2_conv = find_scores(img2vec, 49, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czeeYVMqdTrs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "sRQnZb4M9QLq",
    "outputId": "dddf074c-5ab9-406b-df98-16e996ed0e9f"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer1', layer_output_size=64, \n",
    "#     channels=56, return_embedding=True, centre_crop=True)\n",
    "# score_layer2_conv = find_scores(img2vec, 3136, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Jcy9vVC9QLy"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer2', layer_output_size=128, \n",
    "#     channels=28, return_embedding=True, centre_crop=True)\n",
    "# score_layer2_conv = find_scores(img2vec, 784, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dicmv-Fc9QL0"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer3', layer_output_size=256, \n",
    "#     channels=14, return_embedding=True, centre_crop=True)\n",
    "# score_layer2_conv = find_scores(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qwcx0CQY9QL3"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer4', layer_output_size=512, \n",
    "#     channels=7, return_embedding=True, centre_crop=True)\n",
    "# score_layer2_conv = find_scores(img2vec, 49, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PU7SNRyeP7z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_SMXS7Efgz1"
   },
   "source": [
    "## MCNCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer4', layer_output_size=256, \n",
    "#     channels=14, return_embedding=True)\n",
    "# score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TKGEC8ypdO4"
   },
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer3', layer_output_size=256, \n",
    "#     channels=14, return_embedding=True)\n",
    "# score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img2vec = img2vec_pytorch.Img2Vec(\n",
    "#     cuda=True, layer='layer2', layer_output_size=256, \n",
    "#     channels=14, return_embedding=True)\n",
    "# score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing score\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer1', layer_output_size=256, \n",
    "    channels=14, return_embedding=True)\n",
    "score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLp-c5rF5iPN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_SMXS7Efgz1"
   },
   "source": [
    "## MCNCC (Centre crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer4', layer_output_size=256, \n",
    "    channels=14, return_embedding=True, centre_crop=True)\n",
    "score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TKGEC8ypdO4"
   },
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer3', layer_output_size=256, \n",
    "    channels=14, return_embedding=True, centre_crop=True)\n",
    "score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer2', layer_output_size=256, \n",
    "    channels=14, return_embedding=True, centre_crop=True)\n",
    "score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer1', layer_output_size=256, \n",
    "    channels=14, return_embedding=True, centre_crop=True)\n",
    "score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_SMXS7Efgz1"
   },
   "source": [
    "## MCNCC (Top crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer4', layer_output_size=256, \n",
    "    channels=14, return_embedding=True, top_crop=True)\n",
    "score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TKGEC8ypdO4"
   },
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer3', layer_output_size=256, \n",
    "    channels=14, return_embedding=True, top_crop=True)\n",
    "score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer2', layer_output_size=256, \n",
    "    channels=14, return_embedding=True, top_crop=True)\n",
    "score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer1', layer_output_size=256, \n",
    "    channels=14, return_embedding=True, top_crop=True)\n",
    "score_layer2_conv = find_scores_mcncc(img2vec, 196, return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLp-c5rF5iPN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLp-c5rF5iPN"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "layer_id = 5\n",
    "model = models.resnet50(pretrained=True)\n",
    "modules = list(model.children())[:layer_id] \n",
    "net_base = nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer3', layer_output_size=256, \n",
    "    channels=14, return_embedding=True)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = img2vec.get_vec(ref_img_list[0]).numpy()\n",
    "# test_vec_list = np.array([img2vec.get_vec(img).numpy() for img in test_img_list])\n",
    "\n",
    "# ref_vec_list = ref_vec_list.reshape(ref_vec_list.shape[0], ref_vec_list.shape[2],ref_vec_list.shape[3]*ref_vec_list.shape[4])\n",
    "# test_vec_list = test_vec_list.reshape(test_vec_list.shape[0], test_vec_list.shape[2], test_vec_list.shape[3]*test_vec_list.shape[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec_list = np.array([img2vec.get_vec(img).numpy() for img in ref_img_list])\n",
    "test_vec_list = np.array([img2vec.get_vec(img).numpy() for img in test_img_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec_list = ref_vec_list.reshape(ref_vec_list.shape[0], ref_vec_list.shape[2],ref_vec_list.shape[3]*ref_vec_list.shape[4])\n",
    "test_vec_list = test_vec_list.reshape(test_vec_list.shape[0], test_vec_list.shape[2], test_vec_list.shape[3]*test_vec_list.shape[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_list = (test_vec_list-test_vec_list.mean(1)[:, None])/test_vec_list.std(1)[:, None]\n",
    "ref_vec_list = (ref_vec_list-ref_vec_list.mean(1)[:, None])/ref_vec_list.std(1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ref_img_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec.scaler(img2vec.to_tensor(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec.to_tensor(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = img.size\n",
    "img.crop((0, 0, width, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(2,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec = img2vec_pytorch.Img2Vec(\n",
    "    cuda=True, layer='layer3', layer_output_size=256, \n",
    "    channels=14, return_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec_list = np.array([img2vec.get_vec(img).numpy() for img in ref_img_list])\n",
    "test_vec_list = np.array([img2vec.get_vec(img).numpy() for img in test_img_list])\n",
    "ref_vec_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec_list = ref_vec_list.reshape(ref_vec_list.shape[0], ref_vec_list.shape[2],ref_vec_list.shape[3]*ref_vec_list.shape[4])\n",
    "test_vec_list = test_vec_list.reshape(test_vec_list.shape[0], test_vec_list.shape[2], test_vec_list.shape[3]*test_vec_list.shape[4])\n",
    "ref_vec_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_list = (test_vec_list-test_vec_list.mean(1)[:, None])/test_vec_list.std(1)[:, None]\n",
    "ref_vec_list = (ref_vec_list-ref_vec_list.mean(1)[:, None])/ref_vec_list.std(1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_vec_list@test_vec_list.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((2,2,2,2))[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_list.mean(2)[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_list-test_vec_list.mean(2)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.tensor([1,2,3.0]).norm(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "10701_anand.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
